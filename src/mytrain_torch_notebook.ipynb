{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9291909",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Code/lightning/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c930623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:13.242481Z",
     "start_time": "2024-01-27T14:16:07.733399Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from mymodel import mygen_model\n",
    "from myutils import LossDisplayer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from mydataset import give_me_dataloader, PairedDataset, give_me_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196706f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:22:29.343855Z",
     "start_time": "2024-01-27T14:22:29.343846Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, ckpt_path, epoch, loss=0.0, state='valid'):\n",
    "    try:\n",
    "        os.makedirs(ckpt_path, exist_ok=True)\n",
    "        fname = os.path.join(ckpt_path, \"bwunet_epoch_%05d_loss_%05.3e.pth\"%(epoch, loss))\n",
    "        if os.path.exists(fname):\n",
    "            fname = fname.split('.pth')[0] + f'_{state}_1.pth'\n",
    "        print('trying to save,,,,', fname)\n",
    "        torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"epoch\"      : epoch,\n",
    "                },\n",
    "                fname,\n",
    "        )\n",
    "    except:\n",
    "        print('something wrong......skip saving model at epoch ', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ec1f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:15.342831Z",
     "start_time": "2024-01-27T14:16:15.337764Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def give_me_visualization(model, dataloader, device):\n",
    "    pbar = tqdm(dataloader)\n",
    "    for idx, pairs in enumerate(pbar):\n",
    "        ## for tensorboard viz\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # get data\n",
    "        item_in, item_gt = pairs\n",
    "        if device== 'mps':\n",
    "            item_in = item_in.type(torch.float32)\n",
    "            item_gt = item_gt.type(torch.float32)\n",
    "        item_in = item_in.to(device)\n",
    "        item_gt = item_gt.to(device)\n",
    "\n",
    "        # forward\n",
    "        item_out = model(item_in)\n",
    "\n",
    "        # diff\n",
    "        item_diff = torch.abs(item_out)\n",
    "\n",
    "        ## normalize for grid view\n",
    "        item_in = (item_in + 1) / 2\n",
    "        item_gt = (item_gt + 1) / 2\n",
    "        item_diff = (item_diff + 2) / 4\n",
    "        item_out = (item_out + 1) / 2\n",
    "\n",
    "        # get grid view\n",
    "        item_in = vutils.make_grid(item_in, padding=2, normalize=True)\n",
    "        item_gt = vutils.make_grid(item_gt, padding=2, normalize=True)\n",
    "        item_diff = vutils.make_grid(item_diff, padding=2, normalize=True)\n",
    "        item_out = vutils.make_grid(item_out, padding=2, normalize=True)\n",
    "\n",
    "        top_images = torch.cat((item_in.cpu(), item_gt.cpu()), dim=2)\n",
    "        bot_images = torch.cat((item_diff.cpu(), item_out.cpu()), dim=2)\n",
    "        viz_images = torch.cat((top_images.cpu(), bot_images.cpu()), dim=1)\n",
    "\n",
    "        return viz_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f352f",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014c5e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:17.567175Z",
     "start_time": "2024-01-27T14:16:17.565242Z"
    }
   },
   "outputs": [],
   "source": [
    "bwtest=True\n",
    "# bwtest=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8fabb",
   "metadata": {},
   "source": [
    "# Device selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1eaea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:19.055614Z",
     "start_time": "2024-01-27T14:16:19.052222Z"
    }
   },
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Train Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc07c20",
   "metadata": {},
   "source": [
    "# ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1de53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:20.740885Z",
     "start_time": "2024-01-27T14:16:20.737892Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name      = 'bwunet'\n",
    "dataset_path    = '/Users/bw/Dataset/MIPI_demosaic_hybridevs'\n",
    "myepoch         = 100\n",
    "input_size      = 128\n",
    "batch_size      = 128\n",
    "learning_rate   = 1e-4\n",
    "checkpoint_path = 'model_dir_torch/ckpt'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "if '/content/drive/MyDrive' in cwd:\n",
    "    dataset_path = '/content/drive/MyDrive/Datasets/MIPI_tetra_hybridenvs'\n",
    "\n",
    "print('model_name = ', model_name)\n",
    "print('input_size = ', input_size)\n",
    "print('device = ', device)\n",
    "print('dataset_path = ', dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b40f1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9a048",
   "metadata": {},
   "source": [
    "### Data gathering & shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59113518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:24.867627Z",
     "start_time": "2024-01-27T14:16:22.898921Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = os.path.join(dataset_path)\n",
    "print('base_path: ', base_path)\n",
    "pnames_in = glob.glob(os.path.join(base_path, 'train/pairs', \"*_in.npy\"))\n",
    "pnames_gt = glob.glob(os.path.join(base_path, 'train/pairs', \"*_gt.npy\"))\n",
    "pnames_viz_in = glob.glob(os.path.join(base_path, 'viz/pairs', \"*_in.npy\"))\n",
    "pnames_viz_gt = glob.glob(os.path.join(base_path, 'viz/pairs', \"*_gt.npy\"))\n",
    "\n",
    "\n",
    "pnames_in.sort()\n",
    "pnames_gt.sort()\n",
    "pnames_viz_in.sort()\n",
    "pnames_viz_gt.sort()\n",
    "\n",
    "\n",
    "flen = len(pnames_gt)\n",
    "print(flen)\n",
    "\n",
    "order = np.arange(flen)\n",
    "np.random.shuffle(order)\n",
    "print(order)\n",
    "\n",
    "# shuffle\n",
    "pnames_in = [pnames_in[x] for x in order]\n",
    "pnames_gt = [pnames_gt[x] for x in order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a711e",
   "metadata": {},
   "source": [
    "### Split train & valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb479c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:26.507057Z",
     "start_time": "2024-01-27T14:16:26.497944Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_split = 0.05\n",
    "number_train_set = int(flen*(1-validation_split))\n",
    "number_valid_set = flen - number_train_set\n",
    "print(\"-->>>>\",number_train_set, number_valid_set)\n",
    "\n",
    "pnames_train_in = pnames_in[:number_train_set]\n",
    "pnames_train_gt = pnames_gt[:number_train_set]\n",
    "\n",
    "pnames_valid_in = pnames_in[number_train_set:]\n",
    "pnames_valid_gt = pnames_gt[number_train_set:]\n",
    "\n",
    "if bwtest: # for test purpose\n",
    "    pnames_train_in = pnames_in[:batch_size]\n",
    "    pnames_train_gt = pnames_gt[:batch_size]\n",
    "\n",
    "    pnames_valid_in = pnames_in[batch_size:batch_size*2]\n",
    "    pnames_valid_gt = pnames_gt[batch_size:batch_size*2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c107e",
   "metadata": {},
   "source": [
    "### transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1771a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:27.739284Z",
     "start_time": "2024-01-27T14:16:27.737079Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = {'train': give_me_transform('train'),\n",
    "             'valid': give_me_transform('valid'),\n",
    "             'viz':   give_me_transform('viz')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252b8e0",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16419a1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:28.953703Z",
     "start_time": "2024-01-27T14:16:28.949963Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataloader\n",
    "dataloader = {'train': give_me_dataloader(PairedDataset(pnames_train_in, \n",
    "                                                        pnames_train_gt, \n",
    "                                                        transform['train'], \n",
    "                                                        device), batch_size),\n",
    "              'valid': give_me_dataloader(PairedDataset(pnames_valid_in,\n",
    "                                                        pnames_valid_gt, \n",
    "                                                        transform['valid'], \n",
    "                                                        device), batch_size),\n",
    "              'viz'  : give_me_dataloader(PairedDataset(pnames_viz_in,   \n",
    "                                                        pnames_viz_gt,   \n",
    "                                                        transform['viz'],   \n",
    "                                                        device), batch_size) }\n",
    "\n",
    "nsteps={}\n",
    "for state in ['train', 'valid', 'viz']:\n",
    "    nsteps[state] = len(dataloader[state])\n",
    "    print('len(%s): '%state, len(dataloader[state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b5890",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59c307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:30.508735Z",
     "start_time": "2024-01-27T14:16:30.413267Z"
    }
   },
   "outputs": [],
   "source": [
    "model = mygen_model('bwunet').to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3883da0",
   "metadata": {},
   "source": [
    "# Save onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a36ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:16:32.648029Z",
     "start_time": "2024-01-27T14:16:32.101711Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 128, 128, device=device, requires_grad=False)\n",
    "with torch.no_grad():\n",
    "    os.makedirs('onnx', exist_ok=True)\n",
    "    torch.onnx.export(model.eval(), dummy_input,\n",
    "                      os.path.join('onnx',  f\"{model_name}.onnx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9659d",
   "metadata": {},
   "source": [
    "# Load ckpt if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d213a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:17:50.210688Z",
     "start_time": "2024-01-27T14:17:50.203103Z"
    }
   },
   "outputs": [],
   "source": [
    "if (checkpoint_path is not None) and \\\n",
    "    os.path.exists(checkpoint_path) and \\\n",
    "    (len(os.listdir(checkpoint_path) ) > 0) :\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "else:\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "    epoch = 0\n",
    "\n",
    "# make train mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01059bb",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601d964",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:17:54.496938Z",
     "start_time": "2024-01-27T14:17:54.495033Z"
    }
   },
   "outputs": [],
   "source": [
    "# criterion_cycle = nn.L1Loss()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f339e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d10267c3",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fd10b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:17:55.913877Z",
     "start_time": "2024-01-27T14:17:55.911832Z"
    }
   },
   "outputs": [],
   "source": [
    "optim_G = optim.Adam(\n",
    "        list(model.parameters()),\n",
    "        lr=learning_rate,\n",
    "        betas=(0.5, 0.999),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ec31d",
   "metadata": {},
   "source": [
    "# Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54be6e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:17:57.286188Z",
     "start_time": "2024-01-27T14:17:57.283856Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_lambda = lambda epoch: 1 - ((epoch - 1) // 100) / (myepoch / 100)\n",
    "scheduler_G = optim.lr_scheduler.LambdaLR(optimizer=optim_G, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c017a0a",
   "metadata": {},
   "source": [
    "# Logger for tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7497c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:17:58.750988Z",
     "start_time": "2024-01-27T14:17:58.747581Z"
    }
   },
   "outputs": [],
   "source": [
    "logpath = os.path.join('model_dir_torch', 'board')\n",
    "os.makedirs(logpath, exist_ok=True)\n",
    "summary = SummaryWriter(logpath)\n",
    "disp_train = LossDisplayer([\"G_train\"])\n",
    "disp_valid = LossDisplayer([\"G_valid\"])\n",
    "disp = {'train':disp_train, 'valid':disp_valid}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f094098",
   "metadata": {},
   "source": [
    "# training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809a6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T14:18:00.279723Z",
     "start_time": "2024-01-27T14:18:00.277259Z"
    }
   },
   "outputs": [],
   "source": [
    "step = {'train':epoch*nsteps['train'], \n",
    "        'valid':epoch*nsteps['train'], \n",
    "        'viz':  epoch*nsteps['train']}\n",
    "\n",
    "loss_best_G = {'train': float('inf'), 'valid': float('inf')}\n",
    "loss_G_train_last = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ce4bb",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3748c7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-27T14:22:57.958Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while epoch < myepoch:\n",
    "    epoch += 1\n",
    "    print(f\"\\nEpoch {epoch}\")\n",
    "\n",
    "    loss_G_total = {'train': 0, 'valid': 0}\n",
    "    for state in ['train', 'valid']:\n",
    "        print('hello ', state)\n",
    "        pbar = tqdm(dataloader[state])\n",
    "        for idx, pairs in enumerate(pbar):\n",
    "            pbar.set_description('Processing %s...  epoch %d' % (state, epoch))\n",
    "\n",
    "            if state == 'train' and idx == 0:\n",
    "                # train mode\n",
    "                model.train()\n",
    "            elif state == 'valid' and idx == 0:\n",
    "                # eval mode\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "            # get data\n",
    "            item_in, item_gt = pairs\n",
    "\n",
    "            if device == 'mps':\n",
    "                item_in = item_in.type(torch.float32)\n",
    "                item_gt = item_gt.type(torch.float32)\n",
    "\n",
    "            # data to device\n",
    "            item_in = item_in.to(device)\n",
    "            item_gt = item_gt.to(device)\n",
    "\n",
    "\n",
    "\n",
    "            # -----------------\n",
    "            # Forward\n",
    "            # -----------------\n",
    "            item_out = model(item_in)\n",
    "\n",
    "            # -----------------\n",
    "            # Train Generator\n",
    "            # -----------------\n",
    "            loss_mse = criterion(item_out, item_gt)\n",
    "\n",
    "            # combine loss and calculate gradients\n",
    "            loss_G = 0\n",
    "            loss_G += loss_mse\n",
    "            loss_G_train_last = loss_G  # for save\n",
    "\n",
    "            step[state] += 1\n",
    "            if state == 'train':\n",
    "                # train mode\n",
    "                optim_G.zero_grad()\n",
    "                loss_G.backward()\n",
    "                optim_G.step()\n",
    "            else:\n",
    "                if idx == 0:\n",
    "                    step['valid'] = step['train']\n",
    "\n",
    "            ## accumulate generator loss in validataion to save best ckpt\n",
    "            loss_G_total[state] += loss_G\n",
    "\n",
    "            # -----------------\n",
    "            # record loss for tensorboard\n",
    "            # -----------------\n",
    "            disp[state].record([loss_G])\n",
    "            if step[state] % 100 == 0 and idx>1:\n",
    "                avg_losses = disp[state].get_avg_losses()\n",
    "                summary.add_scalar(f\"loss_G_{state}\", avg_losses[0], step[state])\n",
    "\n",
    "                print(\n",
    "                    f'{state} : epoch{epoch}, step{step[state]}------------------------------------------------------')\n",
    "                print('loss_G: %.3f, ' % avg_losses[0], end='')\n",
    "                disp[state].reset()\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('hello<<< viz ', state)\n",
    "\n",
    "        viz_images = give_me_visualization(model, dataloader['viz'], device )\n",
    "\n",
    "        summary.add_image('generated pairs', viz_images, step['viz'] )\n",
    "\n",
    "\n",
    "        ## save ckeck point if improved\n",
    "        loss_G_average = loss_G_total[state] / nsteps[state]\n",
    "        if loss_best_G[state] > loss_G_average:\n",
    "            print(f'best {state} ckpt updated!!!  old best {loss_best_G[state]} vs new best {loss_G_average}')\n",
    "            loss_best_G[state] = loss_G_average\n",
    "            summary.add_scalar(f\"loss_best_G{state}\", loss_best_G[state], step[state])\n",
    "\n",
    "            ckpt_path_name_best = os.path.join(checkpoint_path)\n",
    "\n",
    "            save_model(model, ckpt_path_name_best, epoch, loss_best_G[state])\n",
    "            \n",
    "            \n",
    "\n",
    "    ## Step scheduler\n",
    "    scheduler_G.step()\n",
    "\n",
    "    # Save checkpoint for every 5 epoch\n",
    "    if epoch % 5 == 0:\n",
    "        save_model(model, checkpoint_path, epoch, loss_G_train_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437cff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a6946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda4ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b183b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d93185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a76c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebddb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f3f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d2425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439ff1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
