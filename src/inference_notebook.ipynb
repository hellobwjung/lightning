{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4c33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:40:01.958966Z",
     "start_time": "2024-01-25T14:39:58.793223Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob, math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import timeit\n",
    "\n",
    "from myutils_tf import bwutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa182842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:40:01.963141Z",
     "start_time": "2024-01-25T14:40:01.959909Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_model(model_name, model_sig):\n",
    "    base_path = os.path.join('model_dir', 'checkpoint')\n",
    "    structure_path = os.path.join(base_path, model_name + '_model_structure.h5')\n",
    "    ckpt_path = os.path.join(base_path, model_name + '_' + model_sig)\n",
    "    print(structure_path, '\\n', ckpt_path)\n",
    "\n",
    "\n",
    "    # load model structure\n",
    "    model = tf.keras.models.load_model(structure_path)\n",
    "\n",
    "    # find latest weights and load\n",
    "    ckpts = glob.glob(os.path.join(ckpt_path, '*.h5'))\n",
    "    ckpts.sort()\n",
    "    ckpt = ckpts[-1]\n",
    "    model.load_weights(ckpt)\n",
    "\n",
    "    print(ckpt)\n",
    "    # model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d420e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:40:01.967541Z",
     "start_time": "2024-01-25T14:40:01.965139Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'bwunet'\n",
    "model_sig = 'noise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a327ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:40:02.872500Z",
     "start_time": "2024-01-25T14:40:01.968653Z"
    }
   },
   "outputs": [],
   "source": [
    "# get model\n",
    "model = get_model(model_name, model_sig)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae58c68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:40:02.879494Z",
     "start_time": "2024-01-25T14:40:02.876307Z"
    }
   },
   "outputs": [],
   "source": [
    "# cellsize\n",
    "cfa_pattern = 'tetra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52387e9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:40:02.890049Z",
     "start_time": "2024-01-25T14:40:02.883017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path\n",
    "PATH_VAL = '/Users/bw/Dataset/MIPI_demosaic_hybridevs/val/input'\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "if '/content/drive/MyDrive' in cwd:\n",
    "    PATH_VAL = '/content/drive/MyDrive/Datasets/MIPI_tetra_hybridenvs/valid/input'\n",
    "\n",
    "    \n",
    "# get file lists    \n",
    "files = glob.glob(os.path.join(PATH_VAL, '*.npy'))\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb33f5",
   "metadata": {},
   "source": [
    "# utils for patternized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5306fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:40:02.901643Z",
     "start_time": "2024-01-25T14:40:02.892985Z"
    }
   },
   "outputs": [],
   "source": [
    "pad_size = 32\n",
    "patch_size = 128\n",
    "\n",
    "\n",
    "# utils for patternized\n",
    "utils = bwutils(input_type='nonshrink',\n",
    "                cfa_pattern=cfa_pattern,\n",
    "                patch_size=patch_size,\n",
    "                crop_size=patch_size,\n",
    "                input_max=1,\n",
    "                use_unprocess=False,\n",
    "                loss_type=['rgb'],\n",
    "                loss_mode='2norm',\n",
    "                loss_scale=1e4,\n",
    "                cache_enable=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262989c6",
   "metadata": {},
   "source": [
    "# Lets infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3af2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:42:08.371975Z",
     "start_time": "2024-01-25T14:40:02.905432Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# shape = np.load(files[0]).shape\n",
    "# height, width, channels = np.load(files[0]).shape\n",
    "# npatches_y, npatches_x = math.ceil(shape[0]/patch_size), math.ceil(shape[1]/patch_size)\n",
    "# print(arr_pred.shape)\n",
    "start = timeit.timeit()\n",
    "infcnt = 0\n",
    "for idx, file in enumerate(files):\n",
    "    infcnt+=1\n",
    "    arr = np.load(file)    # (0, 1023)\n",
    "    arr = arr / (2**10 -1) # (0, 1)\n",
    "    arr = arr * 2 -1       # (-1, 1)\n",
    "\n",
    "\n",
    "    print('arr.shape', arr.shape)\n",
    "    arr = np.pad(arr, ((pad_size, pad_size), (pad_size, pad_size)), 'symmetric')\n",
    "    print('arr.shape', arr.shape)\n",
    "\n",
    "    # break\n",
    "\n",
    "    height, width = arr.shape\n",
    "    npatches_y = math.ceil((height+2*pad_size) / (patch_size-2*pad_size))\n",
    "    npatches_x = math.ceil((width +2*pad_size) / (patch_size-2*pad_size))\n",
    "\n",
    "\n",
    "    # arr_pred = np.zeros_like(arr)\n",
    "    # arr_pred = arr_pred[...,np.newaxis]\n",
    "    arr_pred = np.zeros(arr.shape + (3,) )\n",
    "    print(idx, file, arr.shape, arr_pred.shape)\n",
    "    # exit()\n",
    "    cnt=0\n",
    "    tcnt= npatches_x*npatches_y\n",
    "    \n",
    "\n",
    "    for idx_y in range(npatches_y):\n",
    "        for idx_x  in range(npatches_x):\n",
    "            if(cnt%10==0):\n",
    "                print(f'{cnt} / {tcnt}')\n",
    "            cnt+=1\n",
    "            sy = idx_y * (patch_size-2*pad_size)\n",
    "            ey = sy + patch_size\n",
    "            sx = idx_x * (patch_size-2*pad_size)\n",
    "            ex = sx + patch_size\n",
    "\n",
    "            if ey >= height:\n",
    "                ey = height-1\n",
    "                sy = height-patch_size-1\n",
    "\n",
    "            if ex >= width:\n",
    "                ex = width-1\n",
    "                sx = width-patch_size-1\n",
    "\n",
    "            arr_patch = arr[sy:ey, sx:ex]\n",
    "            print(\"before:\",np.amin(arr_patch), np.amax(arr_patch))\n",
    "            arr_patch = utils.get_patternized_1ch_to_3ch_image(arr_patch)\n",
    "            print(\"after :\",np.amin(arr_patch), np.amax(arr_patch))\n",
    "            \n",
    "            # print(np.amin(arr_patch), np.amax(arr_patch) )\n",
    "            # exit()\n",
    "            # # pre-process # no gamma & bais for demosaic/remosaic\n",
    "            # arr_patch = arr_patch**(1/2.2)\n",
    "\n",
    "            # prediction\n",
    "            pred = model.predict(arr_patch[np.newaxis,...])\n",
    "            # print(pred.shape)\n",
    "\n",
    "            # exit()\n",
    "\n",
    "            # post-process\n",
    "            arr_pred[sy+pad_size:ey-pad_size, sx+pad_size:ex-pad_size, :] = \\\n",
    "                        pred[0, pad_size:-pad_size, pad_size:-pad_size, :]\n",
    "                        #  (pred[0, pad_size:-pad_size, pad_size:-pad_size, :]+1)/2 #  (-1, 1) -> (0, 1)\n",
    "            print(np.amin(arr_patch), np.amax(arr_patch), np.amin(arr_pred), np.amax(arr_pred))\n",
    "#             exit()\n",
    "    \n",
    "    # exit()\n",
    "\n",
    "    # arr_pred.astype(np.uint8)\n",
    "    arr_pred = arr_pred[pad_size:-pad_size, pad_size:-pad_size, :]\n",
    "    arr_pred = (arr_pred+1) / 2 # normalized from (-1, 1) to (0,1)\n",
    "    img_pred = Image.fromarray((arr_pred*255).astype(np.uint8))\n",
    "    # name = os.path.join(PATH_PIXELSHIFT, f'inf_{model_name}_{model_sig}_%02d.png'%(idx+1))\n",
    "#     name = os.path.join(PATH_VAL, f'inf_{model_name}_{model_sig}_%02d.png'%(idx+1))\n",
    "    name = os.path.join(PATH_VAL,  '%04d.png'%(idx+1))\n",
    "    img_pred.save(name)\n",
    "    print(np.amin(img_pred), np.amax(img_pred), np.amin(arr_pred.astype(np.uint8)), np.amax(arr_pred.astype(np.uint8)))\n",
    "#     break\n",
    "end = timeit.timeit()\n",
    "elapsed = end - start\n",
    "print(\"elapsed time \", elapsed / infcnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a6fabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
